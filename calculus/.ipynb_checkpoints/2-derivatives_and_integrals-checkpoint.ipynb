{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  SOLVING CALCULUS PROBLEMS\n",
    "## Derivatives and Integrals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the Derivative of Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The derivative of a function $y = f(x)$ expresses the rate of change in the dependent variable, $y$, with respect to the independent variable, $x$. It’s denoted as either $f′(x)$ or $dy/dx$. We can find the derivative of a function by creating an object of the `Derivative` class. Let’s use the previous function representing the motion of a car as an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Derivative(5*t**2 + 2*t + 8, t)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sympy import Symbol, Derivative #1\n",
    "t = Symbol('t')\n",
    "St = 5*t**2 + 2*t + 8\n",
    "Derivative(St, t) #2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the `Derivative` class at (1). At (2), we create an object of the `Derivative` class. The two arguments passed while creating the object are the function `St` and the symbol `t`, which corresponds to the variable $t$. As with the `Limit` class, an object of the `Derivative` class is returned, and the derivative is not actually calculated. We call the `doit()` method on the unevaluated Derivative object to find the derivative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10*t + 2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = Derivative(St, t)\n",
    "d.doit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expression for the derivative turns out to be `10*t + 2`. Now, if we want to calculate the value of the derivative at a particular value of $t$—say, $t = t_1$ or $t = 1$—we can use the `subs()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10*t1 + 2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.doit().subs({t:'t1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.doit().subs({t:1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s try a complicated arbitrary function with x as the only variable: $(x^3 + x^2 + x)\\times(x^2 + x)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2*x + 1)*(x**3 + x**2 + x) + (x**2 + x)*(3*x**2 + 2*x + 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sympy import Derivative, Symbol\n",
    "x = Symbol('x')\n",
    "f = (x**3 + x**2 + x)*(x**2+x)\n",
    "Derivative(f, x).doit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may consider this function the product of two independent functions, which means that, by hand, we’d need to make use of the *product rule* of differentiation to find the derivative. But we don’t need to worry about that here because we can just create an object of the `Derivative` class to\n",
    "do that for us. Try out some other complicated expressions, such as expressions involving trigonometric functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *A Derivative Calculator*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s write a derivative calculator program, which will take a function as input and then print the result of differentiating it with respect to the variable specified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDerivative calculator\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a function: \n",
      "Enter the variable to differentiate with respect to: \n",
      "Invalid input\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Derivative calculator\n",
    "'''\n",
    "from sympy import Symbol, Derivative, sympify, pprint\n",
    "from sympy.core.sympify import SympifyError\n",
    "def derivative(f, var):\n",
    "    var = Symbol(var)\n",
    "    d = Derivative(f, var).doit()\n",
    "    pprint(d)\n",
    "if __name__=='__main__':\n",
    "    f = input('Enter a function: ') #1\n",
    "    var = input('Enter the variable to differentiate with respect to: ')\n",
    "    try:\n",
    "        f = sympify(f) #2\n",
    "    except SympifyError:\n",
    "        print('Invalid input')\n",
    "    else:\n",
    "        derivative(f, var) #3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At (1), we ask the user to input a function for which the derivative is to be found, and then we ask for the variable with respect to which the function is to be differentiated. At (2), we convert the input function into a `SymPy` object using the `sympify()` function. We call this function in a try...except block so that we can display an error message in case the user enters an invalid input. If the input expression is a valid expression, we call the derivative function at (3), passing the converted expression and the variable with respect to which the function is to be differentiated as arguments.\n",
    "\n",
    "In the `derivative()` function, we first create a `Symbol` object that corresponds to the variable with respect to which the function is to be differentiated. We use the label var to refer to this variable. Next, we create\n",
    "a `Derivative` object that passes both the function to differentiate and the `symbol` object var. We immediately call the `doit()` method to evaluate the derivative, and we then use the `pprint()` function to print the result so that it appears close to its mathematical counterpart. A sample execution of the program follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Enter a function: 2*x**2 + 3*x + 1\n",
    "Enter the variable to differentiate with respect to: x \n",
    "4·x + 3`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here’s a sample run when used with a function of two variables:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Enter a function: 2*x**2 + y**2\n",
    "Enter the variable to differentiate with respect to: x\n",
    "4·x`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Calculating Partial Derivatives*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous program, we saw that it’s possible to calculate the derivative of a multivariable function with respect to any variable using the Derivative class. This calculation is usually referred to as *partial differentiation*, with *partial* indicating that we assume only one variable varies while the others are fixed.\n",
    "Let’s consider the function $f(x, y) = 2xy + xy^2$. The partial differentiation of $f(x, y)$ with respect to $x$ is\n",
    "\n",
    "$$\\frac{\\partial f}{\\partial x} = 2y + y^2$$\n",
    "\n",
    "The preceding program is capable of finding the partial derivative because it’s just a matter of specifying the right variable:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Enter a function: 2*x*y + x*y**2\n",
    "Enter the variable to differentiate with respect to: x\n",
    "y2 + 2·y`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**\n",
    "*A key assumption I’ve made in this notebook is that all the functions we’re calculating the derivative of are differentiable in their respective domains.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Higher-Order Derivatives and Finding the Maxima and Minima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, creating the derivative object using the `Derivative` class finds the first-order derivative. To find higher-order derivatives, simply specify the order of the derivative to calculate as the third argument when you create the `Derivative` object. In this section I will show you how to use the first- and second-order derivative of the function to find its maxima and minima on an interval.\n",
    "\n",
    "\n",
    "Consider the function $x^5 − 30x^3 + 50x$, defined on the domain $[−5, 5]$. Note that I have used square brackets to indicate a closed domain, indicating that the variable $x$ can assume any real value greater than or equal to $−5$ and less than or equal to $5$ (see Figure 1-3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='fig3.png', style='width:450px' />\n",
    "*Figure 1-3: Plot of the function x^5 − 30x^3 + 50x, where −5 ≤ x ≤ 5*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graph, we can see that the function attains its minimum value on the interval $−2 ≤ x ≤ 0$ at the point $B$. Similarly, it attains its maximum value on the interval $0 ≤ x ≤ 2$ at the point $C$. On the other hand, the function attains its maximum and minimum values on the entire domain of $x$ that we’ve considered here at the points $A$ and $D$, respectively. Thus, when we consider the function on the whole interval $[−5, 5]$, the points $B$ and $C$ are referred to as a *local minimum* and a *local maximum*, respectively, while the points $A$ and $D$ are the *global maximum* and the *global minimum*, respectively.\n",
    "\n",
    "The term *extremum* (plural extrema) refers to the points where the function attains a local or global maximum or minimum. If $x$ is an extremum of the function $f(x)$, then the first-order derivative of $f$ at $x$, denoted $f′(x)$, must vanish. This property shows that a good way to find possible extrema is to try to solve the equation $f′(x) = 0$. Such solutions are called *critical points* of the function. Let’s try this out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5*x**4 - 90*x**2 + 50"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sympy import Symbol, solve, Derivative\n",
    "x = Symbol('x')\n",
    "f = x**5 - 30*x**3 + 50*x\n",
    "d1 = Derivative(f, x).doit()\n",
    "d1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have calculated the first-order derivative, $f′(x)$, we’ll solve $f′(x) = 0$ to find the critical points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-sqrt(-sqrt(71) + 9),\n",
       " sqrt(-sqrt(71) + 9),\n",
       " -sqrt(sqrt(71) + 9),\n",
       " sqrt(sqrt(71) + 9)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critical_points = solve(d1)\n",
    "critical_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numbers in the list `critical_points` shown here correspond to the points $B, C, A,$ and $D,$ respectively. We will create labels to refer to these points, and then we can use the labels in our commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = critical_points[2]\n",
    "B = critical_points[0]\n",
    "C = critical_points[1]\n",
    "D = critical_points[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because all the critical points for this function lie within the considered interval, they are all relevant for our search for the global maximum and minimum of $f(x)$. We may now apply the so-called *second derivative* test to narrow down which critical points could be global maxima or minima.\n",
    "\n",
    "First, we calculate the second-order derivative for the function $f(x)$. Note that to do so, we enter `2` as the third argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20*x*(x**2 - 9)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2 = Derivative(f, x, 2).doit()\n",
    "d2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we find the value of the second derivative by substituting the value of each of the critical points one by one in place of $x$. If the resulting value is less than $0$, the point is a local maximum; if the value is greater than $0$, it’s a local minimum. If the resulting value is $0$, then the test is inconclusive and we cannot deduce anything about whether the critical point $x$ is a local minimum, maximum, or neither."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127.661060789073"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2.subs({x:B}).evalf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-127.661060789073"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2.subs({x:C}).evalf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-703.493179468151"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2.subs({x:A}).evalf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "703.493179468151"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2.subs({x:D}).evalf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the second derivative test at the critical points tells us that the points $A$ and $C$ are local maxima and the points $B$ and $D$ are local minima. \n",
    "\n",
    "The global maximum and minimum of $f(x)$ on the interval $[−5, 5]$ is attained either at a critical point $x$ or at one of the endpoints of the domain $(x = −5 and x = 5)$. We have already found all of the critical points, which are the points $A, B, C,$ and $D$. The function cannot attain its global minimum\n",
    "at either of the critical points $A$ or $C$ because they are local maximums. By similar logic, the function cannot attain its global maximum at $B$ or $D$.\n",
    "\n",
    "\n",
    "Thus, to find the global maximum, we must compute the value of $f(x)$ at the points $A, C, −5,$ and $5$. Among these points, the place where $f(x)$ has the largest value must be the global maximum.\n",
    "We will create two labels, `x_min` and `x_max`, to refer to the domain boundaries and evaluate the function at the points `A, C, x_min,` and `x_max`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "705.959460380365"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_min = -5\n",
    "x_max = 5\n",
    "f.subs({x:A}).evalf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.0846626340294"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.subs({x:C}).evalf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "375.000000000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.subs({x:x_min}).evalf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-375.000000000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.subs({x:x_max}).evalf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By these calculations, as well as by examining the function value at all the critical points and the domain boundaries (Figure 1-3), we see that the point $A$ turns out be the global maximum.\n",
    "Similarly, to determine the global minimum, we must compute the values of $f(x)$ at the points $B, D, −5,$ and $5$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-25.0846626340294"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.subs({x:B}).evalf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-705.959460380365"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.subs({x:D}).evalf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "375.000000000000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.subs({x:x_min}).evalf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-375.000000000000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.subs({x:x_max}).evalf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The point where $f(x)$ has the smallest value must be the global minimum for the function; this turns out to be point D$.$ This method for finding the extrema of a function—by considering the function’s value at all of the critical points (after potentially discarding some via the second derivative test) and boundary values—will always work as long as the function is twice differentiable. That is, both the first and second derivative must exist everywhere in the domain.\n",
    "\n",
    "For a function such as $e^x$, there might not be any critical points in the domain, but in this case the method works fine: it simply tells us that the extrema occur at the domain boundary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the Global Maximum Using Gradient Ascent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes we’re just interested in finding the global maximum for a function instead of all the local and global maxima and minima. For example, we might want to discover the angle of projection for which a ball will cover the maximum horizontal distance. We’re going to learn a new, more practical approach to solve such a problem. This approach makes use of the first derivative only, so it’s applicable only to functions for which the first derivative can be calculated.\n",
    "\n",
    "This method is called the *gradient ascent method*, which is an iterative approach to finding the global maximum. Because the gradient ascent method involves lots of computation, it’s the perfect kind of thing to solve programmatically rather than by hand. Let’s try it out using the example problem of finding the angle of projection. Here is the derived expression\n",
    "\n",
    "$$t_{flight} = \\frac{u sin{\\theta}}{g}$$\n",
    "\n",
    "to calculate the time of flight for a body in projectile motion that’s thrown with a velocity $u$ at an angle $\\theta$. The range of a projectile, $R$, is the total horizontal distance traveled by the projectile and is given by the product of $u_x × t_{flight}$. Here, $u_x$ is the horizontal component of the initial velocity and is equal to $u\\cos\\theta$. Substituting the formulas for $u_x$ and $t_{flight}$, we get the expression\n",
    "\n",
    "$$R = u\\cos\\theta \\times \\frac{2u sin{\\theta}}{g} = \\frac{u^2 sin{2\\theta}}{g}$$\n",
    "\n",
    "The plot in Figure 1-4 shows values of $\\theta$ between $0$ and $90$ degrees and the corresponding range (distance traveled) for each angle. From the graph, we can see that the maximum range is obtained when the angle of projection is around $45$ degrees. We’ll now learn to use the gradient ascent method to find this value of $\\theta$ numerically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='fig7-4.png', style='width:450px' />\n",
    "\n",
    "*Figure 1-4: The range of a projectile thrown with an initial velocity of 25 m/s with varying angles of projection*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient ascent method is an iterative method: we start with an initial value of $\\theta$—say, $0.001$, or $\\theta_{old} = 0.001$—and gradually get closer to the value of $\\theta$ that corresponds to the maximum range (Figure 1-5). The step that gets us closer is the equation\n",
    "\n",
    "$$\\theta_{new} = \\theta_{old} + \\lambda\\frac{dR}{d\\theta}$$\n",
    "\n",
    "where $\\lambda$ is the step size and\n",
    "\n",
    "$$\\frac{dR}{d\\theta}$$\n",
    "\n",
    "is the derivative of R with respect to $\\theta$. Once we set $\\theta_{old} = 0.001$, we do the following:\n",
    "\n",
    "1. Calculate θnew using the preceding equation.\n",
    "2. If the absolute difference $\\theta_{new} − \\theta_{old}$ is greater than a value, $\\epsilon$, we set $\\theta_{old} = \\theta_{new}$ and return to step 1. Otherwise, we go to step 3.\n",
    "3. $\\theta_{new}$ is an approximate value of $\\theta$ for which $R$ has the maximum value.\n",
    "The value of epsilon ($\\epsilon$) determines when we decide to stop the iteration\n",
    "of the algorithm. It is discussed in “The Role of the Step Size and Epsilon” later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='fig7-5.png', style='width:450px' />\n",
    "\n",
    "*Figure 1-5: The gradient ascent method takes us iteratively toward the maximum point of the function.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following `grad_ascent()` function implements the gradient ascent algorithm. The parameter `x0` is the initial value of the variable at which to start the iteration, `f1x` is the derivative of the function whose maximum we want to find, and `x` is the `Symbol` object corresponding to the variable for the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nUse gradient ascent to find the angle at which the projectile\\nhas maximum range for a fixed velocity, 25 m/s\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Use gradient ascent to find the angle at which the projectile\n",
    "has maximum range for a fixed velocity, 25 m/s\n",
    "'''\n",
    "import math\n",
    "from sympy import Derivative, Symbol, sin\n",
    "def grad_ascent(x0, f1x, x):\n",
    "    epsilon = 1e-6 #1\n",
    "    step_size = 1e-4 #2\n",
    "    x_old = x0 #3\n",
    "    x_new = x_old + step_size*f1x.subs({x:x_old}).evalf() #4\n",
    "    while abs(x_old - x_new) > epsilon: #5\n",
    "               x_old = x_new\n",
    "               x_new = x_old + step_size*f1x.subs({x:x_old}).evalf()\n",
    "    return x_new\n",
    "\n",
    "def find_max_theta(R, theta): #6\n",
    "    # Calculate the first derivative\n",
    "    R1theta = Derivative(R, theta).doit()\n",
    "    theta0 = 1e-3\n",
    "    theta_max = grad_ascent(theta0, R1theta, theta)\n",
    "    return theta_max #7\n",
    "    if __name__ == '__main__':\n",
    "        g = 9.8\n",
    "        # Assume initial velocity\n",
    "        u = 25\n",
    "        # Expression for range\n",
    "        theta = Symbol('theta')\n",
    "        R = u**2*sin(2*theta)/g #8\n",
    "        theta_max = find_max_theta(R, theta) #9\n",
    "        print('Theta: {0}'.format(math.degrees(theta_max)))\n",
    "        print('Maximum Range: {0}'.format(R.subs({theta:theta_max})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the epsilon value to 1e-6 and the step size to 1e-4 at (1) and (2), respectively. The epsilon value must always be a very small positive value close to 0, and the step size should be chosen such that the variable is incremented in small amounts at every iteration of the algorithm. The choice of the value of epsilon and step size is discussed in a bit more detail in “The Role of the Step Size and Epsilon”.\n",
    "We set `x_old` to `x0` at (3) and calculate `x_new` for the first time at (4). We use the `subs()` method to substitute the value of `x_old` in place of the variable and then use `evalf()` to calculate the numerical value. If the absolute difference `abs(x_old – x_new)` is greater than epsilon, the while loop atykeeps executing, and we keep updating the value of `x_old` and `x_new` as per steps 1 and 2 of the gradient ascent algorithm. Once we’re out of the loop—that is, `abs(x_old – x_new) > epsilon`—we return `x_new`, the variable value corresponding to the maximum function value.\n",
    "\n",
    "We begin to define the `find_max_theta()` function at (6). In this function, we calculate the first-order derivative of `R`; create a label, `theta0`, and set it to 1e-3; and call the `grad_ascent()` function with these two values as arguments, as well as a third argument, the symbol object theta. Once we get the value of $\\theta$ corresponding to the maximum function value (`theta_max`), we return it at (7).\n",
    "\n",
    "Finally, we create the expression representing the horizontal range at (8), having set the initial velocity, `u = 25`, and the theta `Symbol` object corresponding to the angle $\\theta$. Then we call the `find_max_theta()` function with `R` and `theta` at (9).\n",
    "\n",
    "When you run this program, you should see the following output:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Theta: 44.99999978475661\n",
    "Maximum Range: 63.7755102040816`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of $\\theta$ is printed in degrees and turns out to be close to 45 degrees, as expected. If you change the initial velocity to other values, you’ll see that the angle of projection at which the maximum range is reached is always close to 45 degrees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *A Generic Program for Gradient Ascent*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can modify the preceding program slightly to make a generic program for gradient ascent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nUse gradient ascent to find the maximum value of a\\nsingle-variable function\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a function in one variable: 25*25*sin(2*theta)/9.8\n",
      "Enter the variable to differentiate with respect to: theta\n",
      "Enter the initial value of the variable: 0.001\n",
      "theta: 0.785360029379083\n",
      "Maximum value: 63.7755100185965\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Use gradient ascent to find the maximum value of a\n",
    "single-variable function\n",
    "'''\n",
    "from sympy import Derivative, Symbol, sympify\n",
    "def grad_ascent(x0, f1x, x):\n",
    "    epsilon =  1e-6\n",
    "    step_size = 1e-4\n",
    "    x_old = x0\n",
    "    x_new = x_old + step_size*f1x.subs({x:x_old}).evalf()\n",
    "    while abs(x_old - x_new) > epsilon:\n",
    "        x_old = x_new\n",
    "        x_new = x_old + step_size*f1x.subs({x:x_old}).evalf()\n",
    "    return x_new\n",
    "if __name__ == '__main__':\n",
    "    f = input('Enter a function in one variable: ')\n",
    "    var = input('Enter the variable to differentiate with respect to: ')\n",
    "    var0 = float(input('Enter the initial value of the variable: '))\n",
    "    try:\n",
    "        f = sympify(f)\n",
    "    except SympifyError:\n",
    "        print('Invalid function entered')\n",
    "    else:\n",
    "        var = Symbol(var) #1\n",
    "        d = Derivative(f, var).doit() #2\n",
    "        var_max = grad_ascent(var0, d, var) #3\n",
    "        print('{0}: {1}'.format(var.name, var_max))\n",
    "        print('Maximum value: {0}'.format(f.subs({var:var_max})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `grad_ascent()` remains the same here. Now, however, the program asks the user to input the function, the variable in the function, and the initial value of the variable, where gradient ascent will begin. Once we’re sure that SymPy can recognize the user’s input, we create a Symbol object corresponding to the variable at (1), find the first derivative with respect to it at (2), and call the `grad_ascent()` function with these three arguments. The maximum value is returned at (3).\n",
    "\n",
    "Here’s a sample run:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Enter a function in one variable: 25*25*sin(2*theta)/9.8 \n",
    "Enter the variable to differentiate with respect to: theta \n",
    "Enter the initial value of the variable: 0.001\n",
    "theta: 0.785360029379083\n",
    "Maximum value: 63.7755100185965`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function input here is the same as in our first implementation of gradient ascent, and the value of $\\theta$ is printed in radians. Here’s another run of the program, which will find the maximum value for $cosy$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Enter a function in one variable: cos(y)\n",
    "Enter the variable to differentiate with respect to: y \n",
    "Enter the initial value of the variable: 0.01\n",
    "y: 0.00999900001666658\n",
    "Maximum value: 0.999950010415832`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The program also works correctly for a function such as `cos(y) + k`, where `k` is a constant:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Enter a function in one variable: cos(y) + k\n",
    "Enter the variable to differentiate with respect to: y \n",
    "Enter the initial value of the variable: 0.01\n",
    "y: 0.00999900001666658\n",
    "Maximum value: k + 0.999950010415832`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, a function such as `cos(ky)` won’t work because its first-order derivative, `kcos(ky)`, still contains `k`, and SymPy doesn’t know anything about its value. Therefore, SymPy can’t perform a key step in the gradient ascent algorithm—namely, the comparison `abs(x_old - x_new) > epsilon`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *A Word of Warning About the Initial Value*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial value of the variable from which we start the iteration of the gradient ascent method plays a very important role in the algorithm. Consider the function $x5 − 30x3 + 50x$, which we used as an example in Figure 1-3. Let’s find the maximum using our generic gradient ascent program:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Enter a function in one variable: x**5 - 30*x**3 + 50*x \n",
    "Enter the variable to differentiate with respect to: x \n",
    "Enter the initial value of the variable: -2\n",
    "x: -4.17445116397103\n",
    "Maximum value: 705.959460322318`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient ascent algorithm stops when it finds the *closest peak*, which is not always the global maximum. In this example, when you start from the initial value of −2, it stops at the peak that also corresponds to the global maximum (approximately 706) in the considered domain. To verify this further, let’s try a different initial value:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Enter a function in one variable: x**5 - 30*x**3 + 50*x \n",
    "Enter the variable to differentiate with respect to: x \n",
    "Enter the initial value of the variable: 0.5\n",
    "x: 0.757452532565767\n",
    "Maximum value: 25.0846622605419`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the closest peak at which the gradient ascent algorithm stops is not the true global maximum of the function. Figure 1-6 depicts the result of the gradient ascent algorithm for both of these scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='fig7-6.png', style='width:450px' />\n",
    "*Figure 1-6: Results of the gradient ascent algorithm with different initial values. Gradient ascent always takes us to the closest peak.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, when using this method, the initial value must be chosen carefully. Some variations of the algorithm try to address this limitation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *The Role of the Step Size and Epsilon*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the gradient ascent algorithm, the next value for the variable is calculated using the equation\n",
    "\n",
    "$$\\theta_{new} = \\theta_{old} + \\lambda\\frac{dR}{d\\theta}$$\n",
    "\n",
    "where $\\lambda$ is the *step size*. The step size determines the distance of the next\n",
    "step. It should be small to avoid going *over* a peak. That is, if the current value of x is close to the value that corresponds to the maximum value of the function, the next step shouldn’t be beyond the peak. The algorithm will then be unsuccessful. On the other hand, very small values will take longer to calculate. We’ve used a fixed step size of $10^{−3}$, but this may not be the most appropriate value for all functions.\n",
    "\n",
    "The value of epsilon ($\\epsilon$) that determines when we decide to stop the iteration of the algorithm should be a value that’s sufficiently small that we’re convinced the value of $x$ is not changing. We expect the first derivative, $f′(x)$, to be 0 at the maximum point, and ideally the absolute difference $| \\theta_{new} − \\theta_{new} |$ is $0$ (see step 2 of the gradient ascent algorithm). Due to numerical inaccuracies, however, we mayoldnot exactly get a difference of 0; hence, the value of epsilon is chosen to be a value close to 0, which, for all practical purposes, would tell us that the value of $x$ isn’t changing anymore. I have used $10^{−6}$ as the epsilon for all the functions. This value, although sufficiently small and suitable for the functions that have a solution for\n",
    "$f′(x) = 0$, such as $sin(x)$, may not be the right value for other functions. Thus, it’s a good idea to verify the maximum value at the end to ensure its correctness and, if needed, to adjust the value for epsilon accordingly.\n",
    "\n",
    "Step 2 of the gradient ascent algorithm also implies that for the algorithm to terminate, the equation $f′(x) = 0$ must have a solution, which isn’t the case for a function such as ex or $log(x)$. If you provide one of these functions as input to the preceding program, therefore, the program won’t give you a solution, and it will continue running. We can make the gradient ascent program more useful for such cases by incorporating a check for whether $f′(x) = 0$ has a solution. Here’s the modified program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nUse gradient ascent to find the maximum value of a single-variable function.\\nThis also checks for the existence of a solution for the equation f'(x)=0.\\n\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a function in one variable: log(x)\n",
      "Enter the variable to differentiate with respect to: x\n",
      "Enter the initial value of the variable: .1\n",
      "Cannot continue, solution for 1/x=0 does not exist\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Use gradient ascent to find the maximum value of a single-variable function.\n",
    "This also checks for the existence of a solution for the equation f'(x)=0.\n",
    "'''\n",
    "from sympy import Derivative, Symbol, sympify, solve\n",
    "\n",
    "def grad_ascent(x0, f1x, x):\n",
    "# Check if f1x=0 has a solution\n",
    "    if not solve(f1x): #1\n",
    "        print('Cannot continue, solution for {0}=0 does not exist'.format(f1x))\n",
    "        return\n",
    "    epsilon = 1e-6\n",
    "    step_size = 1e-4\n",
    "    x_old = x0\n",
    "    x_new = x_old + step_size*f1x.subs({x:x_old}).evalf()\n",
    "    while abs(x_old - x_new) > epsilon:\n",
    "        x_old = x_new\n",
    "        x_new = x_old + step_size*f1x.subs({x:x_old}).evalf()\n",
    "    return x_new\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    f = input('Enter a function in one variable: ')\n",
    "    var = input('Enter the variable to differentiate with respect to: ')\n",
    "    var0 = float(input('Enter the initial value of the variable: '))\n",
    "    try:\n",
    "        f = sympify(f)\n",
    "    except SympifyError:\n",
    "        print('Invalid function entered')\n",
    "    else:\n",
    "        var = Symbol(var)\n",
    "        d = Derivative(f, var).doit()\n",
    "        var_max = grad_ascent(var0, d, var) \n",
    "        if var_max:\n",
    "            print('{0}: {1}'.format(var.name, var_max))\n",
    "            print('Maximum value: {0}'.format(f.subs({var:var_max})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this modification of the `grad_ascent()` function, we call SymPy’s `solve()` function at (1) to determine whether the equation $f′(x) = 0$, here `f1x`, has a solution. If not, we print a message and return. Another modification appears in the `__main__` block at (2). We check whether the `grad_ascent()` function successfully returned a result; if it did, then we proceed to print the maximum value of the function and the corresponding value of the variable.\n",
    "These changes let the program handle functions such as $log(x)$ and $e^x$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Enter a function in one variable: log(x)\n",
    "Enter the variable to differentiate with respect to: x \n",
    "Enter the initial value of the variable: 0.1\n",
    "Cannot continue, solution for 1/x=0 does not exist`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will see the same for $e^x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**GRADIENT DESCENT ALGORITHM**\n",
    "\n",
    "The reverse algorithm of the gradient ascent algorithm is the gradient descent algorithm, which is a method to find the minimum value of a function. It is similar to the gradient ascent algorithm, but instead of “climbing up” along the function, we “climb down.” Challenge #2  discusses the difference between these two algorithms and gives you an opportunity to implement the reverse one.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the Integrals of Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *indefinite integral*, or the *antiderivative*, of a function $f(x)$ is another function $F(x)$, such that $F′(x) = f(x)$. That is, the integral of a function is another function whose derivative is the original function. Mathematically, it’s written as $F(x) = \\int f(x)dx$. The *definite integral*, on the other hand, is the integral\n",
    "\n",
    "$$\\int^{b}_{a} f(x)dx$$\n",
    "\n",
    "which is really $F(b) − F(a)$, where $F(b)$ and $F(a)$ are the values of the antiderivative of the function at $x = b$ and at $x = a$, respectively. We can find both the integrals by creating an `Integral` object.\n",
    "\n",
    "Here’s how we can find the integral $\\int kx dx$ where $k$ is a constant term:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Integral(k*x, x)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sympy import Integral, Symbol\n",
    "x = Symbol('x')\n",
    "k = Symbol('k')\n",
    "Integral(k*x, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the `Integral` and `Symbol` classes and create two `Symbol` objects corresponding to `k` and `x`. Then, we create an `Integral` object with the function `kx`, specifying the variable to integrate with respect to `x`. Similar to `Limit` and `Derivative` classes, we can now evaluate the integral using the `doit()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "k*x**2/2"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Integral(k*x, x).doit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The integral turns out to be $kx^2/2$. If you calculate the derivative of $kx^2/2$, you’ll get back the original function, $kx$. To find the definite integral, we simply specify the variable, the lower limit, and the upper limit as a tuple when we create the `Integral` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2*k"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Integral(k*x, (x, 0, 2)).doit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result returned is the definite integral\n",
    "\n",
    "$$\\int^{2}_{0} kx dx$$\n",
    "\n",
    "It can be useful to visualize definite integrals by discussing them in a geometric context. Consider Figure 1-7, which shows the graph of the function $f(x) = x$ between $x = 0$ and $x = 5$.\n",
    "\n",
    "Now consider the region under the graph $ABDE$, which is bounded by the $x-axis$, between the points $x = 2$ and $x = 4$—points $A$ and $B$, respectively. The area of the region can be found by adding the area of the square $ABCE$ and the right-angled triangle $ECD$, which is $2 \\times 2 + (1/2) \\times 2 \\times 2 = 6$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='fig7-7.png', style='width:450px' />\n",
    "*Figure 1-7: The definite integral of a function between two points is the area enclosed by the graph of the function bounded by the x-axis.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s now calculate the integral  $\\int^{4}_{2} kx dx$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sympy import Integral, Symbol\n",
    "x = Symbol('x')\n",
    "Integral(x, (x, 2, 4)).doit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of the integral turns out to be the same as the area of the region $ABDE$. This isn’t a coincidence; you’ll find this is true for any function of $x$ for which the integral can be determined. Understanding that the definite integral is the area enclosed by the function between specified points on the $x$-axis is key for understanding probability calculations in random events that involve continuous random variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Density Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s consider a fictional class of students and their grades on a math quiz. Each student can earn a grade between 0 and 20, including fractional grades. If we treat the grade as a random event, the grade itself is a *continuous random variable* because it can have any value between 0 and 20. If we want to calculate the probability of a student getting a grade between 11 and 12, we can’t apply a simplistic approach to probability. To see why, let’s consider the formula, assuming uniform probability,\n",
    "\n",
    "$$P(11 < x < 12) = \\frac{n(E)}{n(S)}$$\n",
    "\n",
    "where $E$ is the set of all grades possible between 11 and 12 and $S$ is the set of all possible grades—that is, all real numbers between 1 and 20. By our definition of the preceding problem, $n(E)$ is infinite because it’s impossible to count all possible real numbers between 11 and 12; the same is true for $n(S)$. Thus, we need a different approach to calculate the probability.\n",
    "\n",
    "A probability density function, $P(x)$, expresses the probability of the value of a random variable being close to $x$, an arbitrary value. It can also tell us the probability of $x$ falling within an interval. That is, if we knew the probability density function representing the probability of grades in our fictional class, calculating $P(11 < x < 12)$ would give us the probability that we’re looking for. But how do we calculate this? It turns out that this probability is the area enclosed by the graph of the probability density function and the $x$-axis between the points $x = 11$ and $x = 12$. Assuming an arbitrary probability density function, Figure 1-8 demonstrates this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='fig7-8.png' style='width:450px' />\n",
    "*Figure 1-8: A probability density function for grades on a math quiz*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already know that this area is equal to the value of the integral,\n",
    "\n",
    "$$\\int_{11}^{12} p(x) dx;$$\n",
    "\n",
    "thus, we have an easy way to find the probability of the grade lying between 11 and 12. With the math out of the way, we can now find out what the probability is. The probability density function we assumed earlier is the function\n",
    "\n",
    "$$\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{(x-10)^2}{2}},$$\n",
    "\n",
    "where $x$ is the grade obtained. This function has been chosen so that the probability of the grade being close to 10 (either greater or less than) is high but then decreases sharply. Now, let’s calculate the integral\n",
    "\n",
    "$$\\int_{11}^{12} p(x) dx,$$\n",
    "with $p(x)$ being the preceding function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.135905121983278"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sympy import Symbol, exp, sqrt, pi, Integral\n",
    "x = Symbol('x')\n",
    "p = exp(-(x - 10)**2/2)/sqrt(2*pi)\n",
    "Integral(p, (x, 11, 12)).doit().evalf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the `Integral` object for the function, with `p` representing the probability density function that specifies that we want to calculate the definite integral between 11 and 12 on the $x$-axis. We evaluate the function using `doit()` and find the numerical value using `evalf()`. Thus, the probability that a grade lies between 11 and 12 is close to 0.14."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**THE PROBABILITY DENSITY FUNCTION: A CAVEAT**\n",
    "\n",
    "Strictly speaking, this density function assigns a nonzero probability to grades less than 0 or greater than 20. However, as you can check using the ideas from this section, the probability of such an event is so small that it is negligible for our purposes.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A probability density function has two special properties: (1) the function value for any x is always greater than 0, as probability can’t be less than 0, and (2) the value of the definite integral\n",
    "\n",
    "$$\\int_{-\\infty}^{\\infty} f(x) dx$$\n",
    "\n",
    "is equal to 1. The second property merits some discussion. Because $p(x)$ is a probability density function, the area enclosed by it, which is also the integral\n",
    "\n",
    "$$\\int_{a}^{b} p(x) dx,$$\n",
    "\n",
    "between any two points, $x = a$ and $x = b$, gives us the probability of $x$ lying between $x = a$ and $x = b$. This also means that no matter what the values of $a$ and $b$ are, the value of the integral must not exceed 1 because the probability can’t be greater than 1 by definition. Hence, even if $a$ and $b$ are very large values such that they tend to $-\\infty$ and $\\infty$, respectively, the value of the integral will still be 1, as we can verify ourselves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.00000000000000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sympy import Symbol, exp, sqrt, pi, Integral, S\n",
    "x = Symbol('x')\n",
    "p = exp(-(x-10)**2/2)/sqrt(2*pi)\n",
    "Integral(p, (x, S.NegativeInfinity, S.Infinity)).doit().evalf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`S.NegativeInfinity` and `S.Infinity` denote the negative and positive infinity that we then specify as the lower and upper limits, respectively, while creating the Integral object.\n",
    "\n",
    "When we’re dealing with continuous random variables, a tricky situation can arise. In discrete probability, the probability of an event such as a fair six-sided die rolling a 7 is 0. We call an event for which the probability is 0 an *impossible* event. In the case of continuous random variables, the probability of the variable assuming any exact value is 0, even though it may be a *possible* event. For example, the grade of a student being exactly 11.5 is possile, but due to the nature of continuous random variables, the probability is 0. To see why, consider that the probability will be the value of the integral\n",
    "\n",
    "$$\\int_{11.5}^{11.5} p(x) dx$$\n",
    "\n",
    "Because this integral has the same lower and upper limits, its value is 0. This is rather unintuitive and paradoxical, so let’s try to understand it.\n",
    "\n",
    "Consider the range of grades we addressed earlier—0 to 20. The grade a student can obtain can be any number in this interval, which means there is an infinite number of numbers. If each number were to have an equal probability of being selected, what would that probability be? According\n",
    "to the formula for discrete probability, this should be $1/\\infty$, which means a very small number. In fact, this number is so small that for all practical purposes, it’s considered 0. Hence, the probability of the grade being 11.5 is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What You Learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you learned how to find the limits, derivatives, and integrals of functions. You learned about the gradient ascent method for finding the maximum value of a function and saw how you can apply integration principles to calculate the probability of continuous random variables. Next, you have a few tasks to attempt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Programming Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following challenges build on what you’ve learned in this notebook. You can find solutions in the Solutions notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #2: Implement the Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient descent method is used to find the minimum value of a function. Similar to the gradient ascent method, the gradient descent method is an iterative method: we start with an initial value of the variable and gradually get closer to the variable value that corresponds to the minimum value of the function. The step that gets us closer is the equation\n",
    "\n",
    "$$x_{new} = x_{old} - \\lambda \\frac{df}{dx}$$\n",
    "\n",
    "where $\\lambda$ is the step size and\n",
    "\n",
    "$$\\frac{df}{dx}$$\n",
    "\n",
    "is the result of differentiating the function. Thus, the only difference from the gradient ascent method is how we obtain the value of `x_new` from `x_old`. \n",
    "\n",
    "Your challenge is to implement a generic program using the gradient descent algorithm to find the minimum value of a single-variable function specified as input by the user. The program should also create a graph of the function and show all the intermediate values it found before finding the minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nUse gradient descent to find the minimum value of a single-variable function.\\nThis also checks for the existence of a solution for the equation f'(x)=0.\\n\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a function in one variable: 3*x**2 + 2*x\n",
      "Enter the variable to differentiate with respect to: x\n",
      "Enter the initial value of the variable: .1\n",
      "x: -0.331668643986980\n",
      "Minimum value: -0.333325019761474\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8f6d451518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "Use gradient descent to find the minimum value of a single-variable function.\n",
    "This also checks for the existence of a solution for the equation f'(x)=0.\n",
    "'''\n",
    "from sympy import Derivative, Symbol, sympify, solve\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def grad_descent(x0, f1x, x):\n",
    "# Check if f1x=0 has a solution\n",
    "    if not solve(f1x): #1\n",
    "        print('Cannot continue, solution for {0}=0 does not exist'.format(f1x))\n",
    "        return\n",
    "    epsilon = 1e-6\n",
    "    step_size = 1e-4\n",
    "    x_old = x0\n",
    "    x_new = x_old - step_size*f1x.subs({x:x_old}).evalf()\n",
    "    \n",
    "    X_traversed = []\n",
    "    \n",
    "    while abs(x_old - x_new) > epsilon:\n",
    "        X_traversed.append(x_new)   # builds list of all x values tried along the way\n",
    "        x_old = x_new\n",
    "        x_new = x_old - step_size*f1x.subs({x:x_old}).evalf()\n",
    "    \n",
    "    return x_new, X_traversed\n",
    "\n",
    "def frange(start, final, interval):\n",
    "    numbers = []\n",
    "    while start < final:\n",
    "        numbers.append(start)\n",
    "        start = start + interval\n",
    "    return numbers\n",
    "\n",
    "def create_plot(X_traversed, f, var):\n",
    "    x_val = frange(-1, 1, 0.01)\n",
    "    f_val = [f.subs({var: x}) for x in x_val]\n",
    "    plt.plot(x_val, f_val, 'bo')\n",
    "    \n",
    "    f_traversed = [f.subs({var: x}) for x in X_traversed]\n",
    "    plt.plot(X_traversed, f_traversed, 'r.')\n",
    "    plt.legend(['Function', 'Intermediate Points'], loc='best')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    f = input('Enter a function in one variable: ')\n",
    "    var = input('Enter the variable to differentiate with respect to: ')\n",
    "    var0 = float(input('Enter the initial value of the variable: '))\n",
    "  \n",
    "    try:\n",
    "        f = sympify(f)\n",
    "    except SympifyError:\n",
    "        print('Invalid function entered')\n",
    "    else:\n",
    "        var = Symbol(var)\n",
    "        d = Derivative(f, var).doit()\n",
    "        var_min, X_traversed = grad_descent(var0, d, var) \n",
    "        if var_min:\n",
    "            print('{0}: {1}'.format(var.name, var_min))\n",
    "            print('Minimum value: {0}'.format(f.subs({var:var_min})))\n",
    "            \n",
    "    create_plot(X_traversed, f, var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## #3: Area Between Two Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We learned that the integral\n",
    "\n",
    "$$\\int_{a}^{b} f(x) dx$$\n",
    "\n",
    "expresses the area enclosed by the function $f(x)$, with the x-axis between $x = a$ and $x = b$. The area between two curves is thus expressed as the integral\n",
    "\n",
    "$$\\int_{a}^{b} (f(x)-g(x)) dx$$\n",
    "\n",
    "where $a$ and $b$ are the points of intersection of the two curves with $a < b$. The function $f(x)$ is referred to as the *upper function* and $g(x)$ as the *lower function*. Figure 1-9 illustrates this, assuming $f(x) = x$ and $g(x) = x^2$, with a = 0 and b = 1.\n",
    "\n",
    "Your challenge here is to write a program that will allow the user to input any two single-variable functions of $x$ and print the enclosed area between the two. The program should make it clear that the first function entered should be the upper function, and it should also ask for the values of $x$ between which to find the area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='fig7-9.png' style='width:450px' />\n",
    "\n",
    "*Figure 1-9: The functions f(x) = x and g(x) = x2 enclose an area between x = 0 and x = 1.0.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the upper function in one variable: x+1\n",
      "Enter the lower function in the same variable: x*exp(-x**2)\n",
      "Enter the variable of interest: x\n",
      "Enter the lower end of the range to evaluate: 0\n",
      "Enter the upper end of the range to evaluate: 2\n",
      "Area between the curves: 3.50915781944437\n"
     ]
    }
   ],
   "source": [
    "from sympy import Integral, Symbol, sympify, SympifyError\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    f = input('Enter the upper function in one variable: ')\n",
    "    g = input('Enter the lower function in the same variable: ')\n",
    "    var = input('Enter the variable of interest: ')\n",
    "    a = float(input('Enter the lower end of the range to evaluate: '))\n",
    "    b = float(input('Enter the upper end of the range to evaluate: '))\n",
    "  \n",
    "    try:\n",
    "        f = sympify(f)\n",
    "    except SympifyError:\n",
    "        print('Invalid upper function entered')\n",
    "    try:\n",
    "        g = sympify(g)\n",
    "    except SympifyError:\n",
    "        print('Invalid lower function entered')\n",
    "    else:\n",
    "        var = Symbol(var)\n",
    "        result = Integral(f - g, (var, a, b)).doit()\n",
    "        print('Area between the curves: {0}'.format(result))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### #4: Finding the Length of a Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s say you just completed cycling along a road that looks roughly like Figure 1-10. Because you didn’t have an odometer, you want to know whether there’s a mathematical way to determine the distance you cycled. First, we’ll need to find an equation—even an approximation will do—that describes this path."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='fig7-10.png' style='width:450px' />\n",
    "\n",
    "*Figure 1-10: An approximation of the cycling path*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how it looks very similar to the quadratic functions you learned about in algebra? In fact, for this challenge, let’s assume that the equation is $y=f(x)=2x^2 +3x + 1$ and that you cycled from point $A (−5, 36)$ to point $B (10, 231)$. To find the length of this arc—that is, the distance you cycled—we’ll need to calculate the integral\n",
    "\n",
    "$$\\int_{a}^{b}\\sqrt{1+\\left(\\frac{dy}{dx}\\right)^2} dx,$$\n",
    "\n",
    "where $y$ describes the preceding function. Your challenge here is to write a program that will calculate the length of the arc, $AB$. You may also want to generalize your solution so that it allows you to find the length of the arc between any two points for any arbitrary function, $f(x)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a function in one variable: 2*x**2 + 3*x + 1\n",
      "Enter the variable of interest: x\n",
      "Enter starting point of x: -5\n",
      "Enter ending point of x: 10\n",
      "Arc Length: 268.372650946022\n"
     ]
    }
   ],
   "source": [
    "from sympy import Derivative, Integral, Symbol, sympify, SympifyError\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    f = input('Enter a function in one variable: ')\n",
    "    var = input('Enter the variable of interest: ')\n",
    "    a = float(input('Enter starting point of x: '))\n",
    "    b = float(input('Enter ending point of x: '))\n",
    "  \n",
    "    try:\n",
    "        f = sympify(f)\n",
    "    except SympifyError:\n",
    "        print('Invalid upper function entered')\n",
    "    else:\n",
    "        var = Symbol(var)\n",
    "        d = Derivative(f, var).doit()\n",
    "        arc_length = sqrt(1 + (d**2))\n",
    "        result = Integral(arc_length, (var, a, b)).doit().evalf()\n",
    "        print('Arc Length: {0}'.format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
